
name: mydicomapp

services:
  upload:
    build: ./upload
    container_name: node-upload
    networks:
      - dicom-network
    depends_on:
      elasticsearch:
        condition: service_healthy
        restart: true
      converter:
        condition: service_healthy
    environment:
      - LOG_LEVEL=info
      - NUMBER_OF_FILES=50

  scp:
    build: ./scp
    container_name: node-scp
    networks:
      - dicom-network
    ports:
      - "11112:11112"
    depends_on:
      rabbitmq:
        condition: service_healthy
        restart: true
      ipfs:
        condition: service_healthy
        restart: true
    environment:
      - LOG_LEVEL=info
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=${RABBITMQ_PORT}
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASS}
      - RABBITMQ_QUEUE=${RABBITMQ_QUEUE}
      - IPFS_HOST=ipfs
      - IPFS_PORT=5001
    healthcheck:
      test: ["CMD", "sh", "-c", "echo 'Checking if scp is ready' && exit 0"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 50s
  
  converter:
    build: 
      context: ./converter
    container_name: node-converter
    networks:
      - dicom-network
    depends_on:
      rabbitmq:
        condition: service_healthy
        restart: true
      elasticsearch:
        condition: service_healthy
        restart: true
    environment:
      - LOG_LEVEL=info
      - NODE_ENV=development
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_USER=${RABBITMQ_USER}
      - RABBITMQ_PASS=${RABBITMQ_PASS}
      - RABBITMQ_PORT=${RABBITMQ_PORT}
      - RABBITMQ_URL=amqp://rabbitmq:${RABBITMQ_PORT}
      - RABBITMQ_QUEUE=${RABBITMQ_QUEUE}
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=${ES_LOCAL_PORT}
      - ELASTICSEARCH_USER=${ES_LOCAL_USER}
      - ELASTICSEARCH_PASS=${ES_LOCAL_PASSWORD}
      - ELASTICSEARCH_NODE=http://elasticsearch:${ES_LOCAL_PORT}
    healthcheck:
      test: ["CMD", "sh", "-c", "echo 'Checking if converter is ready' && exit 0"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 50s

  web:
    build: 
      context: ./web
    container_name: node-web
    ports:
      - 4004:4000
    networks:
      - dicom-network
    depends_on:
      elasticsearch:
        condition: service_healthy
        restart: true
    environment:
      - LOGLEVEL=debug
      - NODE_ENV=development
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=${ES_LOCAL_PORT}
      - ELASTICSEARCH_USER=${ES_LOCAL_USER}
      - ELASTICSEARCH_PASS=${ES_LOCAL_PASSWORD}
      - ELASTICSEARCH_NODE=http://elasticsearch:${ES_LOCAL_PORT}

  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: node-rabbitmq
    networks:
      - dicom-network
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rdata:/var/lib/rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASS}
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 30s
      timeout: 10s
      retries: 3

  ipfs:
    image: ipfs/kubo:latest
    container_name: node-ipfs
    networks:
      - dicom-network
    ports:
      - "5001:5001"
      - "8080:8080"
      - "4001:4001"
    volumes:
      - ./config/ipfs/001.sh:/container-init.d/001.sh
      - idata:/data/ipfs
      - ./config/ipfs/swarm.key:/data/ipfs/swarm.key
    environment:
      - IPFS_PROFILE=server
      # - PRIVATE_PEER_ID=12D3KooWBizv4ZMcmYksaWUjmJkhrzXQjveMpT4Q32QWUQWcLEds  # 替换为实际的 Private Peer ID
      # - PRIVATE_PEER_IP_ADDR=172.18.0.1  # 替换为实际的 Private Peer IP 地址
      - LIBP2P_FORCE_PNET=1
    healthcheck:
      test: ["CMD", "ipfs", "id"]
      interval: 30s
      timeout: 10s
      retries: 3
    command: ["daemon"]

  kibana_settings:
    depends_on:
      elasticsearch:
        condition: service_healthy
    image: docker.elastic.co/elasticsearch/elasticsearch:${ES_LOCAL_VERSION}
    container_name: node-kibana-settings
    networks:
      - dicom-network
    restart: 'no'
    command: >
      bash -c '
        echo "Setup the kibana_system password";
        start_time=$$(date +%s);
        timeout=120;
        until curl -s -u "elastic:${ES_LOCAL_PASSWORD}" -X POST http://elasticsearch:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_LOCAL_PASSWORD}\"}" -H "Content-Type: application/json" | grep -q "^{}"; do
          if [ $$(($$(date +%s) - $$start_time)) -ge $$timeout ]; then
            echo "Error: Elasticsearch timeout";
            exit 1;
          fi;
          sleep 5;
        done;

        echo "kibana_system password set successfully";
  
      '
  kibana:
    depends_on:
      kibana_settings:
        condition: service_completed_successfully
    image: docker.elastic.co/kibana/kibana:${ES_LOCAL_VERSION}
    container_name: node-kibana
    networks:
      - dicom-network
    volumes:
      - kdata:/usr/share/kibana/data
    ports:
      - 127.0.0.1:${KIBANA_LOCAL_PORT}:5601
    environment:
      - SERVER_NAME=kibana
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_LOCAL_PASSWORD}
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${KIBANA_ENCRYPTION_KEY}
      - ELASTICSEARCH_PUBLICBASEURL=http://localhost:${ES_LOCAL_PORT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://kibana:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 30

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ES_LOCAL_VERSION}
    container_name: node-es
    volumes:
      - edata:/usr/share/elasticsearch/data
      - ./config/elastic/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ./config/elastic/plugins/analysis-pinyin:/usr/share/plugins
    networks:
      - dicom-network
    ports:
      - 127.0.0.1:${ES_LOCAL_PORT}:9200
    environment:
      - discovery.type=single-node
      - ELASTIC_PASSWORD=${ES_LOCAL_PASSWORD}
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=false
      - xpack.license.self_generated.type=basic
      - xpack.ml.use_auto_machine_memory_percent=true
      - ES_JAVA_OPTS=-Xms${ES_LOCAL_HEAP_INIT} -Xmx${ES_LOCAL_HEAP_MAX}
    # ulimits:
    #   memlock:
    #     soft: -1
    #     hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -u elastic:${ES_LOCAL_PASSWORD} http://elasticsearch:${ES_LOCAL_PORT}/_cluster/health?pretty | grep '\"status\" : \"green\"'"
        ]
      interval: 15s
      timeout: 15s
      retries: 10
      start_period: 180s
    entrypoint:
      - bash
      - -c
      - |
        /usr/share/elasticsearch/bin/elasticsearch-plugin install file:///usr/share/plugins/elasticsearch-analysis-pinyin-${ES_LOCAL_VERSION}.zip && \
        /usr/local/bin/docker-entrypoint.sh elasticsearch

volumes:
  kdata:
  edata:
  idata:
  rdata:

networks:
  dicom-network:
